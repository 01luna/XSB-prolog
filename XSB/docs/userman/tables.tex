\newtheorem{exercise}{Exercise}[section]

\chapter{Using Tabling in XSB: A Tutorial Introduction} 
\label{tabling_overview}
%=============================================================

XSB has two ways of evaluating predicates.  The default is to use
Prolog-style evaluation, but by using various declarations a
programmer can use also tabled resolution which allows for a
different, more declarative programming style than Prolog.  In this
section we discuss the various aspects of tabling and how it is
implemented in XSB.  Our aim in this section is to provide a user with
enough information to be able to program productively in XSB.  It is
best to read this tutorial with a copy of XSB handy, since much of the
information is presented through a series of exercises.

For the theoretically inclined, XSB uses SLG resolution which can
compute queries to non-floundering normal programs under the
well-founded semantics \cite{VGRS91}, and is guaranteed to terminate
when these programs have the {\em bounded term-depth property}.  This
tutorial covers only enough of the theory of tabling to explain how to
program in XSB.  For those interested, the web site contain papers
covering in detail various aspects of tabling (often through the links
for individuals involved in XSB).  An overview of SLG resolution, and
practical evaluation strategies for it are provided in
\cite{ChWa96,Swif99b,SaSW99,FSW98}.  The engine of XSB, the SLG-WAM,
is described in \cite{SaSw98,RRSSW98,JFLP-Scheduling, SaSW96,
ChSW95,CAT@PLILP-98} as it is implemented in \version{} and its
performance analyzed.  Examples of large-scale applications that use
tabling are overviewed in \cite{Swif99a,CoDS96,DRW96}.

\section{XSB as a Prolog System}\label{tabling_env}
%===========================================================

Before describing how to program using tabling it is perhaps
worthwhile reviewing some of the goals of XSB 
\begin{enumerate}
\item	To execute tabled predicates at the speed of compiled Prolog.
\item	To ensure that the speed of compiled Prolog is not slowed
	significantly by adding the option of tabling.
\item	To execute that the functionality of Prolog is not compromised
 	by support for tabling.
\item	To provide Prolog functionality in tabled predicates 
	whenever it is semantically sensible to do so.
\item	To provide standard predicates to manipulate tables
	taken as objects in themselves.
\end{enumerate}

Goals 1 and 2 are addressed by XSBs engine, which in \version{} is
based on a memory-copying version of a virtual machine called the
SLG-WAM.  The overhead for SLD resolution using this machine is
negligible.  Thus when XSB is used simply as a Prolog system (i.e., no
tabling is used), it is reasonably competitive with other Prolog
implementations based on a WAM emulator written in C or assembly.  For
example, XSB Version 1.6 is about two to three times slower than
Quintus 3.1.1 or emulated SICStus Prolog 3.1.

Goals 3, 4 and 5 have been nearly met, but there are a few instances
in which interaction of tabling with a Prolog construct has been
accomplished, or is perhaps impossibe.  Accordingly we discuss these
instances throughout this chapter.  XSB is still under development
however, so that future versions may support more transparent mixing
of Prolog and tabled code (e.g. allowing tabled predicates in the
scope of \not) or adding Prolog functionality to tabled predicates
(e.g. allowing non-ground negation in {\tt tnot/1}).

\section{Tabling in Definite Programs}	\label{sec:def}

Definite programs, also called Horn Clause Programs, are those
programs without negation --- In XSB, this means without the {\tt
\verb|\+|/1}, {\tt fail\_if/1}, {\tt not/1} or {\tt tnot/1} operators.
Consider the Prolog program
\begin{center}
\begin{minipage}{3.8in}
\begin{verbatim}
path(X,Y) :- path(X,Z), edge(Z,Y).
path(X,Y) :- edge(X,Y).
\end{verbatim}						       
\end{minipage}
\end{center}
together with the query {\tt ?- path(1,Y)}.  This program has a
simple, declarative meaning: there is a path from {\tt X} to {\tt Y}
if there is a path from {\tt X} to some node {\tt Z} and there is a
path from {\tt Z} to {\tt Y}, or if there is a direct path from {\tt
X} to {\tt Y}.  Prolog, however enters into an infinite loop when
computing an answer to this query.  The inability of Prolog to answer
such queries, which arise frequently, comprises one of its major
limitations as an implementation of logic.

A number of approaches have been developed to address this problem by
reusing partial answers to the query {\tt path(1,Y)}
\cite{Diet87,TaSa86,BMSU86,Viei89,Walk93}. The ideas behind these
algorithms can be described in the following manner.  First, the
implementation keeps track of all calls to tabled predicates, (or {\em
tabled subgoals} such as {\tt path(1,Y)} in the above example.
Whenever a new tabled subgoal $S$ is called, a check is first made to
see whether $S$ is in the table.  If so, $S$ is resolved against
answers in the table; if not $S$ is entered into the table and the
subgoal is resolved against program clauses, as in Prolog.  Answers
are handled in the same way.  When an answer to a tabled subgoal $S$
is derived a check is made against the table for $S$ to see if the
answer is there.  If the answer isn't in the table for $S$, the answer
is added and scheduled to be returned to all instances where $S$ has
been called; if the answer is already in the table, the evaluation
simply fails and backtracks to generate more answers.

Predicates can be declared tabled in a variety of ways.  A common form
is the compiler directive
\[
	{\tt \mbox{:-} table\ } p_1/n_1, \ldots, p_k/n_k.
\]
where $p_i$ is a predicate symbol and $n_i$ is an integer representing
the arity of $p_i$.  This directive can be added to the file
containing the predicate to be tabled and then to compile the file.

\begin{exercise}
Unless otherwise noted, the file table\_examples.P in the directory
\verb|$XSB_DIR/examples| contains all code for the running examples in
this section.  Consult the file into XSB and type the query
\begin{verbatim}
         ?- path(1,Y).
\end{verbatim}
and continue hitting semi-colons until you have exhausted all answers.
Type the query again.  Can you guess why the order of answers is
different?  Now type
\begin{verbatim}
         ?- abolish_all_tables.
\end{verbatim}
and retry the path query.
\end{exercise}

\begin{exercise}
If you are curious, try rewriting the path query as it would be
written in Prolog.  Will it now terminate for the provided {\tt
edge/2} relation?  (Remember, in XSB you can always hit
\verb|<ctrl>-C| if you go into an infinite loop).
\end{exercise}

The return of answers in tabling aids in filtering out redundant
computations -- indeed it is this property which makes tabling
terminate for many classes of programs.  The {\em same generation}
program furnishes a case of the usefulness of tabling for optimizing a
Prolog program.

\begin{exercise} \label{ex:samegen}
If you are {\em still} curious, load in the file {\tt cyl.P} in the
\verb|$XSB_DIR/examples| directory using the command.
\begin{verbatim}
         ?- load_dync(cyl.P).
\end{verbatim}
and then type the query
\begin{verbatim}
         ?- same_generation(X,X),fail.
\end{verbatim}
Now rewrite the {\tt same\_generation/2} program so that it does not
use tabling and retry the same query what happens?  (Be patient --- or
use \verb|<ctrl>-C|).
\end{exercise}

The examples stress two differences between tabling and SLD resolution
beyond termination properties.  First, that each solution to tabled
subgoal is returned only once --- a property that is helpful not only
for {\tt path/2} but also for {\tt same\_generation/2} which
terminates in Prolog.  Second, because answers are sometimes obtained
using program clauses and sometimes using answers, answers may be
returned in an unaccustomed order.

In the language of tabling, the first instance of a tabled subgoal $S$
is called a $generator$ subgoal, and is expanded using program clauses
as in SLD resolution (Prolog).  Subsequent instances of $S$ are
referred to as $consuming$ subgoals and are expanded using answers in
the table for $S$ instead of program clauses.  Because $consuming$
subgoals resolve against unique answers rather than repeatedly against
program clauses, tabling will terminate whenever (1) a finite number
of subgoals are encountered in query evaluation, (2) each of these
subgoals have a finite number of answers.  Indeed, it can be proven
that for any program with the {\em bounded term depth property}
(roughly, where all terms generated in a program have a maximum
depth), SLG computation will terminate.  These programs include the
important class of {\em Datalog} programs.

\paragraph*{Variant and Subsumptive Tabling}
The above description gives the general idea of how tabling affects
definite programs but is imprecise on certain points.  In XSB, a
subgoal subgoals $S_2$ can use a table from $S_1$ if $S_1$ is a {\em
variant} of $S_2$, that is, if $S_1$ and $S_2$ are the same up to
variable renaming.  Other tabling strategies may allow $S_2$ to use
the table of $S_1$ if $S_2$ not more general than $S_1$, or $S_2$ is
{\em subsumed by} $S_1$:
\begin{example}
The terms {\tt p(f(Y),X,1)} and {\tt p(f(Z),U,1)} are variants, but
{\tt p(f(Y),X,1)} and {\tt p(f(Z),Z,1)} are not.  In fact, the former
subsumes the latter.
\end{example}
Just as a subsumption or variance relation can be used to decide when
one subgoal can use the table of another, the two relations can be
used to determine when an answer should be returned.  In XSB's engine,
a derived answer $A$ will be considered new and returned to a subgoal
$S$ only if $A$ is not a variant of some other previously derived
answer for $S$.  In \version{} of XSB, subgoal subsumption is not
supported: although work on an engine that includes subgoal subsumption
is nearing completion.  Answer subsumption, however, can be flexibly
programmed as discussed in Section \ref{sec:table-aggregation}
\footnote{We also note that the library {\sf subsumes} contains
routines for checking variance and subsumption.}.

\paragraph{Cuts and Tabling} \label{sec:cuts}
\index{tabling!cuts}

Tabling integrates well with most Prolog functionality, even for
non-pure Prolog predicates.  Meta-logical predicates like {\tt var/1},
and predicates with side-effects like {\tt read/1} and {\tt write/1}
can be used freely in tabled predicates as long as it is remembered
that only the first call to a goal will execute program clauses: the
rest will look up answers from a table.  

The use of cuts with tabling is more problematic, as can be seen from
the following exercise.

\begin{exercise} \label{ex:nocut}
Consider the program
\begin{verbatim}
:- table cut_p/1,cut_q/1,cut_r/0,cut_s/0.

cut_p(X):- cut_q(X),cut_r.
cut_r:- cut_s.
cut_s:- cut_q(_).
cut_q(1).       cut_q(2).

once(Term):- call(Term),!.
\end{verbatim}
What solutions are derived for the goal {\tt ?- p(X)}?  Suppose that
{\tt cut\_p/1} were rewritten as 
\begin{verbatim}
p1(X):- q1(X),once(r1).
\end{verbatim}

How should this cut over a table affect the answers generated for {\tt
cut\_p/1}?  What happens if you rewrite {\tt p/1} in this way and
compile it in XSB?
\end{exercise}

The solution \version{} of XSB takes to the problem posed in Exercise
\ref{ex:nocut} is to check whether a tabled predicate statically lies
in the scope of a cut at compile time.  If so, the compilation is
aborted.  However, cuts are allowed within tabled predicates, subject
(as always) to the restriction that the scope of a cut cannot include
a call to a tabled predicate.  

\begin{example}
An example of using cuts in a tabled predicate is a tabled
meta-interpreter.
\begin{verbatim}
:- table demo/1.

demo(true).
demo((A,B)):-!,demo(A),demo(B).
demo(C):-call(C).
\end{verbatim}
More elaborate tabled meta-interpreters can be extremely useful, for
instance to implement various extensions of definite or normal
programs.
\end{example}

In \version{} of XSB a ``cut'' over tables occurs only when the user
makes a call to a tabled predicate from the interpreter level, but
does not generate all solutions.  In such a case, the user will see
the warning {\tt "Removing incomplete tables..."} appear.  Any
complete tables will not be removed.  They can be abolished by using
one of XSB's predicates for abolishing tables.

\paragraph*{Potential Pitfalls in Tabling}
While the judicious use of tabling can make some programs faster, its
indiscriminate use can make other programs slower.  Naively tabling
{\tt append/3} is one case
\begin{center}
\begin{minipage}{3.5in}
\begin{verbatim}
append([],L,L).
append([H|T],L,[H|T1]) :- append(T,L,T1).
\end{verbatim}						       
\end{minipage}
\end{center}
can, in the worst case, copy $N$ sublists of the first and third
arguments into the table, transforming a linear algorithm into a
quadratic one.

\begin{exercise} \label{ex:append}
If you need convincing that tabling can sometimes slow a query down,
type the query:
\begin{verbatim}
         ?- genlist(1000,L),prolog_append(L,[a],Out).
\end{verbatim}
and then type the query
\begin{verbatim}
         ?- genlist(1000,L),table_append(L,[a],Out).
\end{verbatim}
{\tt append/3} is a particularly bad predicate to table.  Type the query
\begin{verbatim}
         ?- table_append(L,[a],Out).
\end{verbatim}
(i.e. with no {\tt genlist/2} and backtrack through a few answers.
Will {\tt table\_append/3} ever succeed for this predicate?  Why not?

Suppose DCG predicates (Section \ref{DCGs}) are defined to be tabled.
How is this similar to tabling append?
\end{exercise}

Another issue to be aware of when using tabling in XSB is tracing.
XSB's tracer is a standard 4-port tracer, that interacts with the
engine at each call, exit, redo, and failure of a predicate (see
Chapter \ref{debugging}).  When tabled predicates are traced, these
events may occur in unexpected ways, as the following example shows.

\begin{exercise} \label{ex:scc}

Consider a tabled evaluation when the query {\tt ?- a(0,X)} is given
to the following program
\begin{verbatim}
:- table mut_ret_a/2, mut_ret_b/2.
mut_ret_a(X,Y):- mut_ret_d(X,Y).
mut_ret_a(X,Y):- mut_ret_b(X,Z),mut_ret_c(Z,Y).

mut_ret_b(X,Y):- mut_ret_c(X,Y).
mut_ret_b(X,Y):- mut_ret_a(X,Z),mut_ret_d(Z,Y).

mut_ret_c(2,2).      mut_ret_c(3,3).

mut_ret_d(0,1).	     mut_ret_d(1,2).     mut_ret_d(2,3).
\end{verbatim}
{\tt mut\_ret\_a(0,1)} can be derived immediately from the first
clause of {\tt mut\_ret\_a/2}.  All other answers to the query depend
on answers to the subgoal {\tt mut\_ret\_b(0,X)} which arises in the
evaluation of the second clause of {\tt mut\_ret\_a/2}.  Each answer
to {\tt mut\_ret\_b(0,X)} in turn depends on an answer to {\tt
mut\_ret\_a(0,X)}, so that the evaluation switches back and forth
between deriving answers for {\tt mut\_ret\_a(0,X)} and {\tt
mut\_ret\_b(0,X)}.

Try tracing this evaluation, using creep and skip.  Do you find the
behavior intuitive or not?
\end{exercise}

\paragraph*{Table Directives and Declarations}
Often it is tedious to decide which predicates must be tabled.  To
address this, XSB can automatically table predicates in files.  The
declaration {\tt auto\_table} chooses predicates to table to assist in
termination, while {\tt suppl\_table} chooses predicates to table to
optimize data-oriented queries.  Both are explained in Section
\ref{tabling_directives}.

\index{tabling!dynamic predicates}
\begin{exercise}
The reader may have noted that the command {\tt table} was referred to
as a directive, while {\tt auto\_table} and {\tt suppl\_table} were
both referred to as declarations.  The difference is that the user can
execute a directive at the command line but not a compiler declaration.
For instance, restart XSB and at the XSB prompt, type the directive
\begin{verbatim}
         ?- table(dyn_path/2).
\end{verbatim}
and 
\begin{verbatim}
         ?- load_dyn(dyn_examples).
\end{verbatim}
Try the queries to {\tt path/2} of the previous examples.  Note that
it is important to dynamically load {\tt dyn\_examples.P} ---
otherwise the code in the file will be compiled without knowledge of
the tabling declaration.
\end{exercise}

\section{Stratified Normal Programs}
\index{negation!stratified}

Normal programs extend definite programs to include default negation,
which posits a fact as false if all attempts to prove it fail.  As
shown in Example \ref{ex:Russell}, which presented one of Russell's
paradoxes as a logic program, the addition of default negation allows
logic programs to express contradictions.  As a result, some
assertions, such as {\tt shaves(barber,barber)} may be undefined,
although other facts, such as {\tt shaves(barber,mayor)} may be true.
Formally, the meaning of normal programs may be given using the {\em
well-founded semantics} and it is this semantics that XSB adopts for
negation.

\paragraph*{The Intuition behind Stratified Programs}

Before considering the full well-founded semantics, we discuss how XSB
can be used to evaluate programs with {\em stratified negation}.
Intuitively, a program uses stratified negation whenever there is no
recursion through negation.  Indeed, most programmers, most of the
time, use stratified negation.  
%Refining this intuition can lead to an
%array of stratification classes which we will discuss in Section
%\ref{sec:nonstrat}.

\begin{exercise} \label{ex:win1}
The program
\begin{verbatim}
         win(X):- move(X,Y),tnot(win(Y)).
\end{verbatim}
is stratified when the {\tt move/2} relation is a binary tree.  This
can be seen by loading the file {\tt
\verb|$XSB_DIR/examples/|tree1k.P} along with {\tt table\_examples.P}
and typing the query
% $
\begin{verbatim}
         ?- win(1).
\end{verbatim}
{\tt win(1)} calls {\tt win(2)} through negation, {\tt win(2)} calls
{\tt win(4)} through negation, and so on, but no subgoal ever calls
itself recursively through negation.
\end{exercise}

The previous example of {\tt win/1} over a binary tree is a simple
instance of a stratified program, but it does not even require
tabling.  A more complex example is presented below.

\begin{exercise} \label{ex:lrd}
Consider the query {\tt ?- lrd\_s} to the following program
\begin{verbatim}
lrd_p:- lrd_q,tnot(lrd_r),tnot(lrd_s).
lrd_q:- lrd_r,tnot(lrd_p).
lrd_r:- lrd_p,tnot(lrd_q).
lrd_s:- tnot(lrd_p),tnot(lrd_q),tnot(lrd_r). 
\end{verbatim}
Should {\tt lrd\_s} be true or false?  Try it in XSB.  Using the
intuitive definition of ``stratified'' as not using recursion through
negation, is this program stratified?  Would the program still be
stratified if the order of the literals in the body of clauses for
{\tt lrd\_p}, {\tt lrd\_q}, or {\tt lrd\_r} were changed?
\end{exercise}

The rules for {\tt p}, {\tt q} and {\tt r} are involved in a positive
loop, and no answers are ever produced.  Each of these atoms can be
failed, thereby proving {\tt s}.  Exercise \ref{ex:lrd} thus
illustrates an instance of how tabling differs from Prolog in
executing stratified programs since Prolog would not fail finitely for
this program.

\paragraph*{Completely Evaluated Subgoals}
\index{tabling!complete evaluation}

Knowing when a subgoal is completely evaluated can be useful when
programming with tabling.  Simply put, a subgoal $S$ is {\em completely
evaluated} if an evaluation can produce no more answers for $S$.  The
computational strategy of XSB makes great use of complete evaluation
so that understanding this concept and its implications can be of
great help to a programmer.

Consider a simple approach to incorporating negation into tabling.
Each time a negative goal is called, a separate table is opened for
the negative call.  This evaluation of the call is carried on to
termination.  If the evaluation terminates, its answers if any, are
used to determine the success of failure of the calling goal.  This
general mechanism underlies early formulations for tabling stratified
programs \cite{KeTo88,Seki89}.  Of course this method may not be
efficient.  Every time a new negative goal is called, a new table must
be started, and run to termination.  We would like to use information
already derived from the computation to answer a new query, if at all
possible --- just as with definite programs.

XSB addresses this problem by keeping track of the {\em state} of each
subgoal in the table.  A call can have a state of {\em complete}, {\em
incomplete} or {\em not\_yet\_called}.  
%The value $not\_yet\_called$
%means that there is in fact no table entry.  
Calls that do have table entries may be either $complete$ or
$incomplete$.  A subgoal in a table is marked $complete$ only after it
is determined to be completely evaluated; otherwise the subgoal is
$incomplete$.  If a tabled subgoal is not present in the table, it is
termed {\em not\_yet\_called}.  XSB contains predicates that allow a
user to examine the state of a given table (Section
\ref{tabling_predicates}).

Using these concepts, we can overview how tabled negation is evaluated
for stratified programs.  If a literal {\tt tnot(S)} is called, where
{\tt S} is a tabled subgoal, the evaluation checks the state of {\tt
S}.  If {\tt S} is $complete$ the engine simply determines whether the
table contains an answer for {\tt S}.  Otherwise the engine $suspends$
the computation path leading to {\tt tnot(S)} until {\tt S} is
completed (and calls {\tt S} if necessary).  Whenever a suspended
subgoal {\tt tnot(S)} is completed with no answers, the engine resumes
the evaluation at the point where it had been suspended.  We note that
because of this behavior, tracing programs that heavily use negation
may produce behavior unexpected by the user.


\paragraph*{{\tt tnot/1} vs. \not }
\index{{\tt tnot/1}}
\index{\not}

Subject to some semantic restrictions, an XSB programmer can intermix
the use of tabled negation ({\tt tnot/1}) with Prolog's negation
(\not, or equivalently {\tt fail\_if/1} or {\tt not/1}).  These
restrictions are discussed in detail below --- for now we focus on
differences in behavior or these two predicates in stratified
programs.  Recall that ${\tt '\backslash+'(S)}$ calls $S$ and if $S$
has a solution, Prolog , executes a cut over the subtree created by
${\tt '\backslash+'(S)}$, and fails.  {\tt tnot/1} on the other hand,
does not execute a cut, so that all subgoals in the computation path
begun by the negative call will be completely evaluated.  The major
reason for not executing the cut is to insure that XSB evaluates
ground queries to Datalog programs with negation with polynomial data
complexity.  As seen in Section \ref{sec:cuts}, this property cannot
be preserved if negation ``cuts'' over tables.

There are other small differences between {\tt tnot/1} and \not
illustrated in the following exercise.

\begin{exercise}
In general, making a call to non-ground negative subgoal in Prolog may
be unsound (cf. \cite{Lloy84}), but the following program illustrates
a case in which non-ground negation is sound.
\begin{verbatim}
ngr_p:- \+ ngr_p(_).
ngr_p(a).
\end{verbatim}
Its tabled analog is 
\begin{verbatim}
:- table ngr_tp/1.
ngr_tp:- tnot(ngr_tp(_)).
ngr_tp(a).
\end{verbatim}
\version{} of XSB will flounder on the call to {\tt ngr\_tp}, but not
on the call to {\tt ngr\_p/0}.  

The description of {\tt tnot/1} in Section \ref{sec:control} describes
other small differences between \not and {\tt tnot/1} as implemented
in XSB.
\end{exercise}

Before leaving the subject of stratification, we note that the
concepts of stratification also underly XSB's evaluation of tabled
findall: {\tt tfindall/3}.  Here, the idea is that a program is
stratified if it contains no loop through tabled findall (See the
description of predicate {\tt tfindall/3} on
page~\pageref{tfindall/3}).

\subsection{Non-stratified Programs}
\index{negation!unstratified}

As discussed above, in stratified programs, facts are either true or
false, while in non-stratified programs facts may also be undefined.
XSB represents undefined facts as {\em conditional answers}.

\paragraph*{Conditional Answers}
\index{tabling!conditional answers}

\begin{exercise}
Consider the behavior of the {\tt win/1} predicate from Exercise
\ref{ex:win1}.
\begin{verbatim}
         win(X):- move(X,Y),tnot(win(Y)).
\end{verbatim}
when the when the {\tt move/2} relation is a cycle.  Load the file
{\tt \verb|$XSB_DIR/examples|cycle1k.P} into XSB and again type the
query {\tt ?- win(1)}.  Does the query succeed?  Try {\tt
tnot(win(1))}.

Now import {\tt get\_residual/2} via the command
\begin{verbatim}
?- import get_residual/2 from tables.
\end{verbatim}
Can you guess what is happening with this non-stratified program?
\end{exercise}

The predicate {\tt get\_residual/2} (Section \ref{tabling_predicates})
unifies its first argument with a tabled subgoal and its second
argument with the (possibly empty) delay list of that subgoal.  The
truth of the subgoal is taken to be conditional on the truth of the
elements in the delay list.  Thus {\tt win(1)} is conditional on {\tt
tnot(win(2))}, {\tt win(2)} in {\tt tnot(win(3))} and so on until {\tt
win(1023)} which is conditional on {\tt win(1)}.

From the perspective of the well-founded semantics, {\tt win(1)} is
undefined.  Informally, true answers in the well-founded semantics are
those that have a (tabled) derivation.  False answers are those for
which all possible derivations fail --- either finitely as in Prolog
or by failing positive loops.  {\tt win(1)} fits in neither of these
cases -- there is no proof of {\tt win(1)}, yet it does not fail in
the sense given above and is thus undefined.

However this explanation does not account for why undefined answers
should be represented as conditional answers, or why a query with a
conditional answer {\em and} its negation should both succeed.  These
features arise from the proof strategy of XSB, which we now examine in
more detail.

\begin{exercise} \label{ex:simpl}
Consider the program
\begin{verbatim}
:- table simpl_p/1,simpl_r/0,simpl_s/0.
simpl_p(X):- tnot(simpl_s).

simpl_s:- tnot(simpl_r).
simpl_s:- simpl_p(X).

simpl_r:- tnot(simpl_s),simpl_r.
\end{verbatim}
Is {\tt simpl\_p(X)} true for any {\tt X}?  Try the query {\tt ?-
simpl\_p(X)} -- be sure to backtrack through all possible answers.
Now try the query again.  What could possibly account for this
behavior?
\end{exercise}

At this point, it is worthwhile to examine closely the evaluation of
the program in Exercise \ref{ex:simpl}.  The query {\tt simpl\_p(X)}
calls {\tt simpl\_s} and {\tt simpl\_r} and executes the portion of
the program shown below in bold:
\begin{center}
\begin{tabular}{l}
{\bf simpl\_p(X):- tnot(simpl\_s).} \\
\\
{\bf simpl\_s:- tnot(simpl\_r).} \\
{\bf simpl\_s:- simpl\_p(X).} \\
\\
{\bf simpl\_r:- tnot(simpl\_s)},{\it simpl\_r.}
\end{tabular}
\end{center}
Based on evaluating only the bold literals, the three atoms are all
undefined since they are neither proved true, nor fail.  However if
the evaluation could only look at the literal in italics, {\em
simpl\_r}, it would discover that {\em simpl\_r} is involved in a
positive loop and, since there is only one clause for {\em simpl\_r},
the evaluation could conclude that the atom was false.  This is
exactly what XSB does, {\tt delays} the evaluation of {\tt
tnot(simpl\_s)} in the clause for {\tt simpl\_r} and looks ahead to
the next literal in the body of that clause.  This action of looking
ahead of a negative literal is called {\em delaying}.  A delayed
literal is moved into the {\em delay list} of a current path of
computation.  Whenever an answer is derived, the delay list of the
current path of computation is copied into the table.  If the delay
list is empty, the answer is unconditional; otherwise it is
conditional.  Of course, for definite programs any answers will be
unconditional --- we therefore omited delay lists when discussing such
programs.

In the above program, delaying occurs for the negative literals in
clause for {\tt simpl\_p(X)}, {\tt simpl\_s}, and {\tt simpl\_r}.
In the first two cases, conditional answers can be derived, while in
the third, {\tt simpl\_r} will fail as mentioned above.  Delayed
literals eventually become evaluated through {\em simplification}.
Consider an answer of the form 
\begin{verbatim}
simpl_p(X):- tnot(simpl_s)|
\end{verbatim}
where the {\tt |} is used to represent the end of the delay list.  If,
after the answer is copied into the table, {\tt simpl\_s} turns out to
be false, (after being initially delayed), the answer can become
unconditional.  If {\tt simpl\_s} turns out to be true, the answer
should be removed, it is false.

In fact, it is this last case that occurs in Exercise \ref{ex:simpl}.
The answer
\begin{verbatim}
simpl_p(X):- tnot(simpl_s)|
\end{verbatim}
is derived, and returned to the user (XSB does not currently print out
the delay list).  The answr is then removed through simplification so
that when the query is re-executed, the answer does not appear.

We will examine in detail how to alter the XSB interface so that
evaluation of the well-founded semantics need not be confusing.  It is
worthwhile to note that the behavior just described is uncommon.

\version\ of XSB handles dynamically stratified programs through
delaying negative literals when it becomes necessary to look to their
right in a clause, and then simplifying away the delayed literals when
and if their truth value becomes known.  However, to ensure
efficiency, literals are never delayed unless the engine determines
them to not to be stratified under the \LRD\ evaluation method.

\paragraph{When Conditional Answers are Needed} \label{sec:lrd}

A good Prolog programmer uses the order of literals in the body of a
clause to make her program more efficient.  However, as seen in the
previous section, delaying can break the order that literals are
evaluated within the body of a clause.  It then becomes natural to ask
if any guarantees can be made that XSB is not delaying literals
unnecessarily.

Such a guarantee can in fact be made, using the concept of {\em
dynamic stratification} \cite{Przy89d}.  Without going into the
formalism of dynamic stratification, we note that a program is
dynamically stratified if and only if it has a two-valued model.  It
is also known that computation of queries to dynamically
stratified programs is not possible under any fixed strategy for
selecting literals within the body of a clause.  In other words, some
mechanism for breaking the fixed-order literal selection strategy must
be used, such as delaying.

However, by redefining dynamic stratification to use an arbitrary
fixed-order literal selection strategy (such as the left-to-right
strategy of Prolog), a new kind of stratification is characterized,
called {\em Left-to-Right Dynamic Stratification}, or {\em
LRD-stratification}.  \LRD{} is not as powerful as dynamic
stratification, but is more powerful than other fixed-order
stratification methods, and it can be shown that for ground programs,
XSB delays only when programs are not \LRD.  In the language of
\cite{SaSW99} XSB is {\em delay minimal}.

\paragraph{Programming in the Well-founded Semantics}
\index{well-founded semantics}

XSB delays literals for non-\LRD{} programs and later simplifies them
away.  But how can the programmer determine when all simplification
has been done?  One method is to use local evaluation, discussed below
in Section \ref{sec:local}.  A second method is to make a top-level
call for a predicate, {\tt p} as follows:
\begin{verbatim}
?- p,fail ; p.
\end{verbatim}
when the second {\tt p} in this query is called, all simplification on
{\tt p} will have been performed.  However, this query will succeed if
{\tt p} is true {\em or} undefined.

\begin{exercise} \label{ex:true-val}
Write a predicate {\tt wfs\_call(?Tpred,?Val)} such that if {\tt
Tpred} is a ground call to a tabled predicate, {\tt
wfs\_call(?Tpred,?Val)} calls {\tt Tpred} and unifies {\tt Val} with
the truth value of {\tt Tpred} under the well-founded semantics.

How would you modify {\tt wfs\_call(?Tpred,?Val)} so that it properly
handled cases in which {\tt Tpred} is non-ground.
\end{exercise}

\paragraph*{Trouble in Paradise: Answer Completion}
\index{tabling!answer completion}

The engine for XSB performs both Prolog style and answer resolution,
along with delay and simplification.  What it does not do is to
perform an operation called {\em answer completion} which is needed in
certain (pathological?) programs.

\begin{exercise}
Consider the following program:
\begin{verbatim}
:- table p/1,r/0,s/0.
ac_p(X):- ac_p(X).
ac_p(X):- tnot(ac_s).

ac_s:- tnot(ac_r).
ac_s:- ac_p(X).

ac_r:- tnot(ac_s),ac_r.
\end{verbatim}
Using either the predicate from Exercise \ref{ex:true-val} or some
other method, determine the truth value of {\tt ac\_p(X)}.  What
should the value be?  (hint: what is the value of {\tt ac\_s/1}?).
\end{exercise}

For certain programs, XSB will delay a literal (such as {\tt ac\_p(X)}
that it will not be able to later simplify away.  In such a case, an
operation, called {\em answer completion} is needed to remove the
clause
\begin{verbatim}
      p(X):- p(X)|
\end{verbatim}
Without answer completion, XSB may consider some answers to be
undefined rather than false.  It is thus is sound, but not complete
for terminating programs to the well-founded semantics.  Answer
completion is not available for \version{} of XSB, as it is expensive
and the need for answer completion arises rarely in practice.  However
answer completion will be included at some level in future versions of
XSB.

\subsection{On Beyond Zebra: Implementing Other Semantics for
Non-stratified Programs}
\index{stable models}

The Well-founded semantics is not the only semantics for
non-stratified programs.  XSB can be used to (help) implement other
semantics that lie in one of two classes.  1) Semantics that extend
the well-founded semantics to include new program constructs; or 2)
semantics that contain the well-founded partial model as a submodel.

An example of a semantics of class 1) is (WFSX) \cite{ADP95}, which
adds explicit (or provable) negation to the default negation used by
the Well-founded semantics.  The addition of explicit negation in
WFSX, can be useful for modeling problems in domains such as diagnosis
and hierarchical reasoning, or domains that require updates
\cite{Leit97}, as logic programs.  WFSX is embeddable into the
well-founded semantics; and this embedding gives rise to an XSB
meta-interpreter, or, more efficiently, to the preprocessor described
in Section {\it Extended Logic Programs} in Volume 2.  See
\cite{Swif99a} for an overview of the process of implementing
extensions of the well-founded semantics.

An example of a semantics of class 2) is the stable model semantics.
Every stable model of a program contains the well-founded partial
model as a submodel.  As a result, the XSB can be used to evaluate
stable model semantics through the {\em residual program}, to which we
now turn.

\paragraph*{The Residual Program}

Given a program $P$ and query $Q$, the residual program for $Q$ and
$P$ consists of all (conditional and unconditional) answers created in
the complete evaluation of $Q$.  

\begin{exercise} \label{ex:pos-delay}
Consider the following program.
\begin{verbatim}
     :- table ppgte_p/0,ppgte_q/0,ppgte_r/0,ppgte_s/0,
              ppgte_t/0,ppgte_u/0,ppgte_v/0.
     ppgte_p:- ppgte_q.          ppgte_p:- ppgte_r.

     ppgte_q:- ppgte_s.          ppgte_r:- ppgte_u.
     ppgte_q:- ppgte_t.          ppgte_r:- ppgte_v.

     ppgte_s:- ppgte_w.          ppgte_u:- undefined.
     ppgte_t:- ppgte_x.          ppgte_v:- undefined.

     ppgte_w:- ppgte(1).         ppgte_x:- ppgte(0).
     ppgte_w:- undefined.        ppgte_x:- undefined.

     ppgte(0).

     :- table undefined/0.
     undefined:- tnot(undefined).
\end{verbatim}
Write a routine that uses {\tt get\_residual/2} to print out the
residual program for the query {\tt ?- ppgte\_p,fail}.  Try altering the
tabling declarations, in particular by making {\tt ppgte\_q/0}, {\tt
ppgte\_r/0}, {\tt ppgte\_s/0} and {\tt ppgte\_t/0} non-tabled.  What
effect does altering the tabling declarations have on the residual
program?
\end{exercise}

When XSB returns a conditional answer to a literal $L$, it does not
propagate the delay list of the conditional answer, but rather delays
$L$ itself, even if $L$ does not occur in a negative loop.  This has
the advantage of ensuring that delayed literals are not propagated
exponentially through conditional answers.

\paragraph*{Stable Models}
\index{negation!stable models}

Stable models are one of the most popular semantics for non-stratified
programs.  The intuition behind the stable model semantics for a
ground program $P$ can be seen as follows.  Each negative literal $not
L$ in $P$ is treated as a special kind of atom called an {\em
assumption}.  To compute the stable model, a guess is made about
whether each assumption is true or false, creating an assumption set,
$A$.  Once an assumption set is given, negative literals do not need
to be evaluated as in the well-founded semantics; rather an evaluation
treats a negative literal as an atom that succeeds or fails depending
on whether it is true or false in $A$.

\begin{example}
Consider the simple, non-stratified program
\begin{center}
\begin{Prog}
writes\_manual(terry)-$\neg$writes\_manual(kostis),has\_time(terry). \\
writes\_manual(kostis)-$\neg$writes\_manual(terry),has\_time(kostis). \\
has\_time(terry). \\
has\_time(kostis). \\
\end{Prog}
\end{center}
there are two stable models of this program: in one {\tt
writes\_manual(terry)} is true, and in another {\tt
writes\_manual(kostis)} is true.  In the Well-Founded model, neither
of these literals is true.  The residual program for the above program
is
\begin{center}
\begin{Prog}
writes\_manual(terry)-$\neg$writes\_manual(kostis). \\
writes\_manual(kostis)-$\neg$writes\_manual(terry). \\
has\_time(terry). \\
has\_time(kostis). \\
\end{Prog}
\end{center}
\end{example}

Computing stable models is an intractable problem, meaning that any
algorithm to evaluate stable models may have to fall back on
generating possible assumption sets, in pathological cases.  For a
ground program, if it is ensured that residual clauses are produced
for {\em all} atoms, using the residual program may bring a
performance gain since the search space of algorithms to compute
stable models will be correspondingly reduced.  In fact, by using XSB
in conjunction with a Stable Model generator, Smodels \cite{NiSi96},
an efficient system has been devised for model checking of concurrent
systems that is 10-20 times faster than competing systems
\cite{LiRS98}.  

\section{Tabled Aggregation} \label{sec:table-aggregation}
\index{tabled aggregation}
\index{{\tt filterReduce/4}}
\index{{\tt filterPO/4}}

The following shortest path predicate is a modification of the {\tt
path/2} predicate of Section \ref{sec:def}:
\begin{center}
\begin{minipage}{3.8in}
\begin{verbatim}
:- table path/3.
path(X,Y,C) :- path(X,Z,C1), edge(Z,Y,C2), C is C1 + C2.
path(X,Y,C) :- edge(X,Y,C).
\end{verbatim}						       
\end{minipage}
\end{center}

\begin{exercise}
{\tt path/3} has a simple declarative meaning: it computes the path
between two vertices of a graph along with the cost of the path.
Since {\tt path/3} is tabled would you expect it to terminate?  Try
the query {\tt ?- path(1,5,X)} over the graph provided in the file
{\tt table\_examples.P}.
\end{exercise}

If we could use tabling to compute the path with least cost, or the
shortest path, the program would not only omit extraneous information,
but it would also terminate.  Recall that for simple horn programs,
variant-based tabling ensures termination by only returning a given
answer $A$ once, and failing on subsequent derivations of $A$.  If
this strategy could be extended so that the engine only returned a new
answer if it was minimal, termination could be ensured.  The XSB
predicate, {\tt filterReduce(?Pred,+Binary\_operator,+Identity,Value)},
does just this.  

\begin{exercise}
The use of {\tt filterReduce/4} can be seen most easily through an
example such as the following, (which uses a closely related predicate
{\tt filterReduce1/4}).
\begin{center}
\begin{minipage}{3.8in}
\begin{verbatim}
shorter_path(X,Y,C) :- filterReduce1(sp(X,Y),min,infinity,C).

sp(X,Y,C) :- shorter_path(X,Z,C1),
             edge(Z,Y,C2),C is C1 + C2.
sp(X,Y,C) :- edge(X,Y,C).

min(X,Y,Y):- \+ number(X),!.
min(X,Y,X):- \+ number(Y),!.
min(One,Two,Min):- One > Two -> Min = Two ; Min = One.
\end{verbatim}						       
\end{minipage}
\end{center}
Note that the library predicate {\tt filterReduce1/4} is tabled, so
that neither {\tt sp/3} nor {\tt shorter\_path/3} need be tabled.  Now
try the query {\tt shorter\_path(1,5,C)}.
\end{exercise}

{\tt filterReduce1((?Pred,+Binary\_operator,+Identity,Value)}, forms a
new predicate out of {\tt Pred} and {\tt Value} to get a new predicate
to call.  {\tt Binary\_Operator} must define a binary function in
which the first two arguments determine the third.  {\tt Id} must be
the identity of {\tt Binary\_operator}.  {\tt Value} becomes the
result of applying {\tt Op} to all the elements in the table that are
variants of {\tt Pred}.  In our case, when a new answer {\tt
sp(X,Y,C)} is derived within {\tt filterReduce1/4}, the later
predicate returns only when {\tt C} is a shorter  path for {\tt X} and
{\tt Y} than any so far derived.

While {\tt shorter\_path/4} terminates, it returns non-optimal
solutions, and these solutions can in principle be costly ---
\cite{JFLP-Scheduling} cites a case in which the shorter path program,
which should be less than cubic in the number of vertices in a graph,
has exponential complexity because of the non-optimal solutions that
are returned.  Fortunately, this has an easy solution.

\begin{exercise}
The actual {\tt shortest\_path} program has the following definition.
\begin{center}
\begin{minipage}{3.8in}
\begin{verbatim}
filterReduce(Call,Op,Id,Res) :- filterReduce1(Call,Op,Id,Res), fail.
filterReduce(Call,Op,Id,Res) :- filterReduce1(Call,Op,Id,Res).

shortest_path(X,Y,C) :- filterReduce(sp(X,Y),min,infinity,C).

sp(X,Y,C) :- shortest_path(X,Z,C1),
             edge(Z,Y,C2),C is C1 + C2.
sp(X,Y,C) :- edge(X,Y,C).

min(X,Y,Y):- \+ number(X),!.
min(X,Y,X):- \+ number(Y),!.
min(One,Two,Min):- One > Two -> Min = Two ; Min = One.
\end{verbatim}						       
\end{minipage}
\end{center}
Once again try the query {\tt shortest\_path(1,5,C)}.
\end{exercise}

By simply failing out of {\tt filterReduce1/4} and then rereading the
maximal value from the table, an efficient {\tt shortest\_path}
algorithm is derived, whose complexity is roughly cubic in the number
or vertices of the graph.  This solution is not general for all
predicates, but does work for deriving the shortest path.  A more
general solution is provided in Section \ref{sec:local}.

{\tt filterReduce/4} is an extremely useful predicate.  It can write
database aggregation functions, such as min, max, count, sum, and
average.  However, it can also be used to implement paraconsistent and
quantitative reasoning through Generalized Annotated Programs
\cite{KiSu92}, as detailed in the section on GAPs in Volume 2 of this
manual.

Several predicates perform tabled aggregation besides {\tt
filterReduce/4}.  One of these is the predicate {\tt
filterPO1(?Pred,?Preference\_structure,+Partial\_order)}.  Analoguosly
to {\tt filterReduce1/4} if {\tt Pred} is an n-ary predicate, {\tt
filterPO/4} forms a (n+1)-ary predicate {\tt Pred1} whose last
argument is {\tt Preference\_structure} and whose functor and all
other arguments are determined by {\tt Pred}.  {\tt
filterPO(?Pred,?Preference\_structure,+Partial\_order)}, then calls
{\tt Pred1} and for each return of {\tt Pred1} fails if there is some
answer already in the table for {\tt filterPO1/4} such that the first
n arguments of {\tt Pred} in the tabled answer unify with the first n
arguments of {\tt Pred} in the return and whose preference structure
(last argument) is preferred to that of the return.  A case study in
the use of {\tt filterPO/4} to construct preference logic grammars can
be found in \cite{CuSW99}.

\subsection{Local Evaluation} \label{sec:local}
\index{Local Scheduling}

For the shortest path example, simply failing until a minimal answer
was derived and then returning that solution was an effective
technique for computing the shortest path.  However, this approach
will not always work.  As we have seen in Exercise \ref{ex:scc},
programs can consist of sets of mutually recursive predicates and in
principle these sets can be arbitrarily large.  If these computations
are to use tabled aggregation, the approach taken by {\tt
filterReduce/4} will not suffice.  To see this, we make the notion of
mutual recursion more precise.  A tabled computation can be viewed as
a directed graph, in which there is a link from one non-completed
tabled predicate $P1$ to a non-completed tabled predicate $P2$ if $P2$
(or $tnot(P2))$ is called by $P1$.  Of course, this graph constantly
changes through an evaluation as resolution proceeds, subgoals are
completed, and so on.  Any directed graph can be uniquely partitioned
into a set of maximal {\em strongly connected components} or SCCs, and
these sets correspond to sets of mutually recursive predicates.  The
SCCs then, are reminiscent of the \LRD stratification discussed in
Section \ref{sec:lrd}, except that both positive and negative links
are counted as dependencies.  From this view, to optimally compute
tabled aggregation, non-optimal answers from a given subgoal $S$ must
be returned within the SCC of $S$, but not outside the SCC.  This
action is performed by {\em Local Scheduling}.

It is illustrative to compare local scheduling to {\em Batched
Scheduling} the default scheduling of XSB.  Batched scheduling returns
answers as they are derived, and resembles Prolog's tuple at a time
scheduling.  Local scheduling was shown to be quite efficient in terms
of time and space in \cite{JFLP-Scheduling}, and is the fastest
scheduling strategy that we know of for computing a sequence of
answers.  The same paper also introduced Local Scheduling, which
computes all answers for each SCC and return only the best answer (or
answers) out of the SCC, when the SCC is completely evaluated ---
exactly the thing for tabled aggregation.

XSB can be configured to use local scheduling via the configuration
option {\tt --enable-local-scheduling} and remaking XSB.  This will
not affect the default version of XSB, which will also remain
available.


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "manual1"
%%% End: 
