\newcommand{\xsbpyversion}{Version 0.3}

\begin{center}
\chapter[XSB and Python]{{\tt xsbpy}: The XSB-Python 3 Interface} \label{chap:xsbpy}
\end{center}

\vspace*{-.30in} 
\begin{center}
{\Large {\bf  \xsbpyversion}}
\end{center}

\begin{center}
  {\Large {\bf By Muthukumar Suresh, Theresa Swift, Carl Andersen}}
\end{center}

\noindent
{\large {\bf {\em This chapter is a draft documentation of beta-level
      software.}}}

%Both XSB and Python are written in C, which makes possible a robust
%and efficient interface.  
%

The new {\tt xsbpy} package provides an efficient and easy way for XSB
to call Python 3 functions and methods.  {\tt xsbpy} leverages the
fact that XSB and most Pythons are written in C, so that both systems
can be readily loaded into the same process. The core interface
routines are also written entirely in C, so the interface is very
efficient and -- it is hoped -- very robust within its known
limitations.\footnote{The {\tt xsbpy} package was partly funded by BBN
  Technologies.}

This chapter first describes how to configure {\tt xsbpy}, followed by
introductory examples.  Next is a more precise description of its
functions, its current limitations followed by some sample
applications and further examples.

\section{Configuration and Loading}

An initial version of a configuration process of {\tt xsbpy} has been
written for Linux and Windows, and is still in the process of being
tested under various configurations.  On these platforms, {\tt xsbpy}
has been tested using versions 3.5 -- 3.8 Python and its
libraries.\footnote{The {\tt xsbpy} configuration script was written
  by Michael Kifer.}

\subsection{Configuring {\tt xsbpy} under Linux with GCC}

In principle, when XSB is configured on Linux, {\tt xsbpy} will also
be configured so that it can be used like any other XSB module.
However, for this configuration to work several things must be in
place.

\begin{itemize}
\item GCC (or some other compiler) must be present and usable by the
  user performing the configuration.

\item A development version of Python 3.x must also be present and
  usable by the user performing the configuration.\footnote{If several
    versions of Python 3.x are installed, the most recent will be used
    by the configurator.}  Thw version must be a CPython version (this
  is the usual implementation of Python), and in addition must also
  contain a version of Python as a shared object ({\tt .so}) file and
  Python header ({\tt .h})files.  The need for a development version
  sometimes requires an additional download of Python.  On Ubuntu,
  while Python is ordinarily downloaded as:

  {\tt apt-get install python3}

\noindent
the shared-object library corresponding to that version must also be
downloaded as, e.g.:

{\tt apt-get install libpython3-dev}

or if using a particular version of Python-3

{\tt apt-get install libpython3.8-dev}

\item Next, the user must have permissions to use {\tt pip} on this
  version of Python, as the configuration process may need to download
  the Python library {\tt find\_libpython}.
\end{itemize}

If there are difficulties in configuring {\tt xsbpy}, it is likely
that one of the above requirements is not met.  However, if these
requirements are met, but the configuration does not work properly, it
is best to check the file {\tt packages/xsbpy/xsb2py\_connect\_defs.h} to see whether
its definitions are correct.  The definitions in this file are used in
{\tt get\_compiler\_options/2} in {\tt init\_xsbpy.P} to properly
compile {\tt xsbpy} and link in {\tt libpython3x.so}.\footnote{If you
  can determine that the required software is present and that there
  is a problem with the configuration please report the problem at
  {\tt https://sourceforge.net/p/xsb/bugs}.}

In Ubuntu Linux, this is all done automatically when {\tt xsbpy} is
consulted into XSB via a normal consult or {\tt ensure\_loaded/[1,2]}.
As part of this process, in {\tt init\_xsbpy.P} the main C code for
{\tt xsbpy} is compiled using gcc compiler options that are
appropriate for the version of libpython used.\footnote{See {\tt
    get\_compiler\_options/2} in {\tt init\_xsbpy.P}.}
When the {\tt xsbpy} module is consulted into XSB, the {\tt libpython}
shared object file (or DLL) is loaded dynamically along with the {\tt
  xsbpy} shared object file.

%If installing {\tt xsbpy} on Ubuntu, the first step is to ensure that
%the proper Python libraries and header files are present.  If using
%Python version 3.7 this command is:
%
%{\tt sudo apt-get install libpython3.7-dev}
%
%For {\tt xsbpy} to work properly in Linux:
%\begin{itemize}
%\item The {\tt xsbpy} code must be compiled and dynamically loaded into XSB.
%\item A version of {\tt libpython.so} also needs to be dynamically
%  loaded into XSB, and configured with the proper C library paths.
%\item The proper paths must be set for the Python Standard Library.
%\item Paths to {\tt xsbpy} and to {\tt xsbpy/apps} must be set up to
 % access both XSB and Python modules.
%\end{itemize}

%\begin{verbatim}
%-I <path to XSB's emu directory>  
%-I/usr/include/python3.7m  -I/usr/include/python3.7  
%-lpython3.7m -L/usr/lib/python3.7 
%-Wl -rpath=/usr/lib/python3.7 -lpython3.7m -L/usr/lib/python3.7 
%-Wl -rpath=/usr/lib/python3.7
%\end{verbatim}

\noindent
%In the above compilation options, {\tt xsbpy} initialization
%configures the path to the XSB {\tt emu} directory but all other paths
%are currently hard-coded.

\subsection{Configuring {\tt xsbpy} under Windows}

\subsection{Configuring {\tt xsbpy} under MacOsX}

\subsection{Testing whether the {\tt xsbpy} configuration was successful}

No matter what platform {\tt xsbpy} is installed on, to test out
whether {\tt xsbpy} has been loaded and is working properly, simply
change the working directory to {\tt packages/xsbpy/test} and execute the
command

\begin{verbatim}
  bash test.sh
\end{verbatim}


\section{Introductory Examples}

We introduce some of the core functionality of {\tt xsbpy} via a
series of simple examples.  As background, when {\tt xsbpy} is loaded,
Python is also loaded and initialized within the XSB process, the core
Prolog modules of {\tt xsbpy} are loaded into XSB, and paths to {\tt
  xsbpy} and its subdirectories are added both to Prolog and to Python
(the latter paths are added by modifying Python's {\tt
  sys.path}). Later, XSB calls Python, Python will search for modules
and packages in the same manner as if it were stand-alone.

\begin{example} \rm {\bf Calling a Python Function (I)}
  %

  {{\em The translation of JSON through xsbpy in this example,
      although it is functional, is mainly presented for pedagogic
      purposes.  In general, we recommend using XSB's native JSON
      interface described in Chapter \ref{chap:json} of this manual.
  }}

  
\noindent  
Consider the following call:

 \begin{verbatim}
pyfunc(xp_json,
       loads('{"name": "Bob", "languages": ["English","French","GERMAN"]}'),
       Ret)
\end{verbatim}
 
\noindent 
which loads the Python {\tt xp\_json} module in {\tt xsbpy/starters}
if needed (and by extension the Python system {\tt json} module), then
calls the Python function

{\tt xp\_json.loads()}

\noindent
with the JSON string
\verb|'{"name": "Bob", "languages": ["English","French","GERMAN"]}'|
as the argument.
This call converts the argument to a Python
dictionary.  In this case, the dictionary would have the Python form:
\begin{verbatim}
{
  "name":"Bob",
  "languages":["English", "French","GERMAN"]
}
\end{verbatim}
Next,
{\tt xsbpy} translates this dictionary to a Prolog term, that can
be pretty printed as:
\begin{verbatim}
pyDict([
        ''(name,'Bob'),
        ''(languages,['English','French','GERMAN'])
        ]).
\end{verbatim}
%%
Note that \verb|''| here is an empty string (i.e., a Prolog 0-length
atom).  XSB uses \verb|''| as a functor for terms that are converted
from or to Python tuples: in this case \verb|''/2| is used.  We call a
term that maps to a Python dictionary either {\em a Python dictionary
  in term form} or just {\em a Prolog dictionary} although the latter
slightly abuses terminology.
\end{example}

Note that although the above example used {\tt xp\_json.loads()}, the
Python system package call {\tt json.loads()} could also have been
used.  Such a switch would not require writing {\em any} special
new Prolog or Python code.  This is in part because Python's basic data
structures -- dictionaries, lists, tuples, sets and so on -- are
mapped to Prolog terms (cf. Section~\ref{sec:bi-translation}).  As a
result, calling Python is often a simple matter of setting up input
terms for a Python function, and processing the terms that Python
returns to Prolog.\footnote{The module {\tt xp\_json} basically
  imports and re-exports {\tt loads()}.}

\begin{example} \rm {\bf Calling a Python Function (II): Glue Code} \label{xsbpy-examp:glue}

\noindent
  A slightly more complex call to Python is:
 \begin{verbatim}
pyfunc(xp_json,prolog_load('test.json'),Ret)
\end{verbatim}

\noindent
which loads a JSON string from the file {\tt test.json} into a Prolog
term.  However, the Python function {\tt json.load()} call requires a
Python file pointer as its input, and Python file pointers do not
correspond to XSB I/O streams.  As we shall see in
Example~\ref{xsbpy-examp:method}, a reference to a Python file pointer
could be passed back to XSB, but in most cases it is probably easiest
to write some simple Python glue code such as:

\begin{verbatim}   
def prolog_load(File):
    with open(File) as fileptr:
        return(json.load(fileptr))
\end{verbatim}
\noindent
As in the previous example, the above Prolog goal produces a Prolog
dictionary corresponding to the JSON file.
\end{example}

\begin{example} \rm {\bf Calling a Python Function (III): Keyword Arguments}
  
\noindent
Python functions often make heavy use of keyword arguments.  These can
be easily handled by {\tt pyfunc/4}:
\begin{verbatim}
pyfunc(xp_json,prolog_dump(Dict,'new.json'),[indent=2],Ret)
\end{verbatim}

\noindent
in which the third argument is a list of {\tt =/2} terms.  This list
is turned into a Prolog dictionary and then translated into Python.
Because {\tt json.dump()} needs a file pointer in the same way {\tt
  json.load()}, glue code will also be needed, but the glue code passes
keyword arguments in the usual manner of Python:
\begin{verbatim}
def prolog_dump(Dict,File,**Features):
    with open(File,"w") as fileptr:
        ret = json.dump(Dict,fileptr,**Features)
        return(ret)
\end{verbatim}
\end{example}

The previous examples have sketched an approach that can efficiently
call virtually any Python function or method,\footnote{{\tt xsbpy}
  does not currently support Python's binary types.}  although it
might require a small amount of glue code.  However, Python methods can
also be called directly.

\begin{example} \rm {\bf Calling a Python Method} \label{xsbpy-examp:method}

\noindent
Consider the following simple Python class:

\begin{verbatim}
class Person:
  def __init__(self, name, age, ice_cream=None):
    self.name = name
    self.age = age
    if favorite_ice_cream is None:
      favorite_ice_cream = 'chocolate'
    self.favorite_ice_cream = favorite_ice_cream

  def hello(self,mytype):
    return("Hello my name is " + self.name + " and I'm a " + mytype)
\end{verbatim}

\noindent
The call

\begin{verbatim}
    pyfunc('Person','Person'(john,35),Obj),
\end{verbatim}
\noindent
creates a new instance of the {\tt Person} class, and returns a
reference to this instance which has a form such as {\tt
  pyObj(p0x7fb1947b0210)}.  XSB can later use this reference to call a
method:
\begin{verbatim}
    pydot('Person',pyObj(p0x7fb1947b0210),hello(programmer),Ret2).
\end{verbatim}

\noindent
which returns the Prolog atom:

{\tt 'Hello my name is john and I'm a programmer'}

\noindent
Although Python methods, like Python functions, can include keyword
arguments, {\tt xsbpy} does not support keyword arguments in {\tt
  pydot/4} because Version 3.9.4 of the Python C API does not permit
this.
\end{example}

\begin{example} \rm {\bf Examining a Python Object} \label{xsbpy-examp:exam-object}

\noindent
Example \ref{xsbpy-examp:method} showed how to create a Python object,
pass it back to Prolog and apply a method to it.  Suppose we create
another {\tt Person} instance:

\begin{verbatim}
    pyfunc('Person','Person'(bob,34),Obj),
\end{verbatim}
\noindent
and later want to find out all attributes of {\tt bob} both explicitly
assigned, and default.  This is easily done by {\tt
  xp\_utils:obj\_dict/2}.  Assuming that {\tt pyObj(p0x7f386e1e9650)}
is the object reference for {\tt bob} in Prolog, the call
\begin{verbatim}
obj_dict(pyObj(p0x7f386e1e9650) ,ObjD ) .
\end{verbatim}
returns
\begin{verbatim}
    ObjD = pyDict([(name,bob),(age,34),(favorite_ice_cream,chocolate)])
\end{verbatim}

There are times when using the dictionary associated with a class is
not appropriate.  For instance, not all Python classes have {\tt
  \_\_dict\_\_} methods defined for them, or only a single attribute
of an object might be required.  In these cases, {\tt pydot/4} can be
used:

\begin{verbatim}
    pydot('Person',pyObj(p0x7f386e1e9650),favorite_ice_cream,I)
\end{verbatim}
\noindent
returns {\tt I = chocolate}.

\noindent

Summarizing from Example~\ref{xsbpy-examp:method} and the above
paragraph, {\tt pydot/4} can be used in two ways.  If the third
argument, {\tt arg3}, in a call to {\tt pydot/4} is a Prolog
structure, {\tt arg3} is interpreted as a method.  In this case, a
Python method is applied to the object, and its return is unified with
the last argument of {\tt pydot/4}. If {\tt arg} is a Prolog atom,
{\tt arg3} is interpreted as attribute of the object.  In this case,
the attribute is accessed and unified with {\tt arg3}.  Note that the
functionality of {\tt pydot/4} is overloaded in analogy to the
functionality of the {\tt '.'} connector in Python.
\end{example}

A great deal of Python functionality is directly available via {\tt
  pyfunc/[3,4]} and {\tt pydot/4}.  In our experience so far, many
Python libraries can be called directly and will ``just work''
immediately.  Cases where glue code is needed include the following.

\begin{itemize}
\item In a case like Example \ref{xsbpy-examp:glue} where a Python
  method or function like {\tt json.load()} requires a Python resource
  as input, a small amount of code might be useful to, say, open a
  file and perform an operation.  However as an alternative, the file
  might be opened, the file pointer passed back to XSB, and the
  function called directly from XSB using the file pointer.

  \item As mentioned, {\tt pydot/4} does not support keyword
    arguments, due to restrictions in the Python C API.

  \item Suppose a class with several attributes is defined as a
    subclass of, say a string type.  Currently {\tt xsbpy} will simply
    pass back such objects as strings, rather than as object
    references.  An example of this in fact occurs in the sample
    interface {\tt xsbpy/starters/xp\_rdflib} (see
    Section~\ref{secLxp-rdflib}).  In the {\tt rdflib} package {\tt
      rdflib.Literal} objects are in fact subclasses of a string type.
    These {\tt rdflib.Literal} objects have additional attributes
    representing language tags and data types; and these attributes
    are critical for RDF I/O from Prolog.  An example of how to handle
    this is seen in {\tt xp\_rdflib.py}, where slightly more elaborate
    glue code is needed to marshal an object's attributes as elements
    of a tuple, and passed back along with the object.\footnote{This
      behavior may change in future versions.}
\end{itemize}

With those disclaimers in mind, all glue code that we have needed to
write so far has been simple and straightforward.

\section{Bi-translation between Prolog Terms and Python Data Structures} \label{sec:bi-translation}

{\tt xsbpy} takes advantage of a C-level bi-translation of a large
portion of Prolog terms and Python data structures: i.e., Python
lists, tuples, dictionaries, sets and other objects are translated to
their Prolog term forms, and Prolog terms of special syntax are
translated to lists, tuples, dictionaries, sets and so on.
Bi-translation is recursive in that any of these data structures can
be nested in other data structures.
     
As mentioned above, when a Python data structure $D$, say a
dictionary, is translated into a Prolog term $T$, $T$ is sometimes
called the {\em term form} of $D$.  Due to a syntactic overlap between
Prolog terms and Python data structures, the Prolog term forms are
easy to translate and use -- and sometimes appear syntactically
identical.

More specifically, bi-translation between Prolog and Python can be
described from the viewpoint of Python types as follows: 

\begin{itemize}
       \item {\em Numeric Types}: Python integers and floats are
         bi-translated to Prolog integers and floats.  Python complex
         numbers are not (yet) translated, and integers are only
         supported for integers between XSB's minimum and maximum
         integer~\footnote{These integers can be obtained by querying
           {\tt current\_prolog\_flag/2}.}
         \begin{itemize}
           \item {\em Boolean Types} are
             translated to integer values: {\tt True} as {\tt 1}
             and {\tt False} as {\tt 0}.
         \end{itemize}
       \item {\em String Types}: Python string types are bi-translated
         to Prolog atoms.  This translation assumes UTF-8 encoding on
         both sides.

         Note that a Python string can be enclosed in either double
         quotes (\verb|''|) or single quotes (\verb|'|).  In
         translating from Python to Prolog, the outer enclosure is
         ignored, so Python {\tt "'Hello'"} is translated to the
         Prolog {\tt '\textbackslash{}'Hello\textbackslash{}'{}'},
         while the Python {\tt '"Goodby"'} is translated to the Prolog
         {\tt '"Goodby"'}.
       \item {\em Sequence Types}:
         \begin{itemize}
           \item Python lists are bi-translated as Prolog lists and
             the two forms are syntactically identical.
           \item A Python tuple of arity {\tt N} is bi-translated with
             a compound Prolog term \verb|''/N| (i.e., the functor is
             the empty string, denoted by two apostrophes).
             \item Python ranges are not (yet) translated (i.e., they
               are returned as terms with functor {\tt pyObj/1}).
         \end{itemize}
       \item {\em Mapping Types}: A Python dictionary is translated
         into the term form:

         {\tt pyDict(DictList)}

         where {\tt DictList} is a list of tuples in term form: 

         {\tt ''(Key,Value)}

         {\tt Key} and {\tt Value} are the translations of any Python
         data structures that are both allowable as a dictionary key
         or value, and supported by {\tt xsbpy}.  For instance, {\tt
           Value} can be (the term form of) a list, a set, a tuple or
         another dictionary.

       \item {\em Set Types}: A Python set {\em S} is translated to
         the term form

         {\tt pySet(SetList)}

         where {\em SetList} is the list containing exactly the
         translated elements of $S$.  Due to Python's implementation
         of sets, there is no guarantee that the order of elements
         will be the same in $S$ and $SetList$.
       \item {\em None Types.} The Python keyword {\tt None} is
         translated to the Prolog atom {\tt 'None'}. 
       \item {\em Binary Types:} are not yet supported.  There are no
         current plans to support this type.
     \item Any Python object {\tt Obj} that is a non-primitive type,
       or of a type that is not translated to a specific Prolog term
       as indicated above is translated to the Prolog term {\tt
         pyObj(Obj)}.  This {\tt pyObj(Obj)} term can be passed back to
       Python and used for a method call or other purpose.
\end{itemize}

Additionally, a user with a minimal knowledge of C can change parts of
the syntax used in Prolog term forms.  The outer functors {\tt
  pyDict}, {\tt pySet} and {\tt pyObj} and the constant {\tt None} can
all be redefined my modifying the file {\tt xsbpy\_defs.h} in the {\tt
  xsbpy} directory.

\section{Usage}

\begin{description}

\ourrepeatmoditem{pyfunc(+Module,+Function,+Kwargs,?Return)}{pyfunc/4}{xsbpy}
\altourmoditem{pyfunc(+Module,+Function,?Return)}{pyfunc/3}{xsbpy}
%
 Ensures that the Python module {\tt Module} is loaded, and calls {\tt
   Module.Function} unifying the return of {\tt Function} with {\tt
   Return}.  A list of keyword arguments may or may not be included.
 For example the goal

\begin{verbatim}
pyfunc(xp_rdflib,rdflib_write_file(Triples,'new_sample.ttl'),
       [format=turtle],Ret).
\end{verbatim}

calls the function {\tt xp\_rdflib.rdflib\_write\_file} to write
{\tt Triples}, a list of triples in Prolog format, to the file {\tt
  new\_sample.ttl} using the {\tt turtle} format.  This format is
specified as a keyword argument to {\tt rdflib\_write\_file()} in the
third argument of {\tt pyfunc/4}.

In general, {\tt Module} must be the name of a Python module or path
represented as a Prolog atom, and {\tt Function} is the invocation of
a Python function in {\tt Module}, where {\tt Function} is a compound
Prolog structure.  Optional keyword arguments are passed in the third
argument as lists of {\tt Key = Value} terms; if no such arguments are
needed, {\tt Kwargs} can be an empty list -- or {\tt pyfunc/3} may be
used.  Finally the return value from {\tt Function} is unified with
{\tt Return}.

Python modules are searched for in the paths maintained in Python's
{\tt sys.path} list.  As indicated below, these Python paths can be
queried from XSB via {\tt py\_lib\_dir/1} and modified via {\tt
  add\_py\_lib\_dir/1}.
     
{\bf Error Cases}
\bi
\item {\tt Module} cannot be found in the current Python search paths:
\bi
\item misc\_error
\ei
\item {\tt Function} does not correspond to a Python function in {\tt Module}
\bi
\item misc\_error
  \ei \ei
%
  In addition, errors thrown by Python are
  caught by XSB and thrown as {\tt misc\_error} errors.

\altourmoditem{pydot(+Module,+ObjRef,+MethAttr,?Ret)}{pydot/4}{xsbpy}
%
Applies a method to {\tt ObjRef}, or obtains an attribute from it.  As
with {\tt pyfunc/[3,4]}, {\tt Module} is a Python module or
path. However, {\tt ObjRef} is a Python object reference in term form
(i.e., a term of the form {\tt pyObj(Ref)} where {\tt Ref} is a Prolog
atom depicting a reference to a Python object). {\tt pydot/4} acts in
one of two ways:
\begin{itemize}
\item If {\tt MethAttr} is a Prolog compound term corresponding to a
  Python method for {\tt ObjRef}, the method is called and its return
  unified with {\tt Ret}.  Unfortunately, due to limitations in the
  Python C API version 3.9.4, keyword arguments cannot be used when
  calling Python method as they can for Python functions.
%
\item If {\tt MethAttr} is a Prolog atom corresponding to the name of
  an attribute of {\tt ObjRef}, the attribute is accessed and unified
  with {\tt Ret}.
\end{itemize}

{\bf Error Cases}
\bi
\item {\tt Module} cannot be found in the current Python search paths:
\bi
\item misc\_error
\ei
\item {\tt ObjRef} is not a Python object reference in Prolog term form:
\bi
\item misc\_error
\ei
\item {\tt MethAttr} is neither a Prolog compound term nor a Prolog atom:
\bi
\item misc\_error \ei \ei In addition, errors thown by Python are
  caught by XSB and re-thrown as {\tt misc\_error} errors.

\ourrepeatmoditem{pp\_py(+Stream,+Term)}{pp\_py/2}{xsbpy}
\altourmoditem{pp\_py(Term)}{pp\_py/1}{xsbpy}
%
Pretty prints the Prolog translation of a Python data structure in
Python-like syntax.  For instance, the term

\begin{verbatim}
pydict([''(name,'Bob'),''(languages,['English','French','GERMAN'])]).
\end{verbatim}

\noindent
is printed as 
\begin{verbatim}
{
  name:'Bob',
  languages:[
   'English','
   'French',
   'GERMAN'
  ]
} 
\end{verbatim}

Such pretty printing can be useful for developing applications such as
the {\tt xsbpy} Elasticsearch interface.

\altourmoditem{add\_py\_lib\_dir(+Path)}{add\_py\_lib\_dir/1}{xsbpy}
%
This convenience predicate allows the user to add a path to the Python
library directories in a manner similar to {\tt add\_lib\_dir/1},
which adds Prolog library directories.

\altourmoditem{py\_lib\_dirs(?Path)}{py\_lib\_dirs/1}{xsbpy}
%
This convenience predicate returns the current Python library
directories as a Prolog list.

\altourmoditem{values(+Dict,+Path,?Val)}{values/3}{xp\_utils}
%
  Convenience predicate to obtain a value from a (possibly nested)
  Prolog dictionary.  The goal

  {\tt values(D,key1,V)}

\noindent
  is equivalent to the
  Python expression {\tt D[key1]} while

  {\tt values(D,[key1,key2,key3],V)}

\noindent
is equivalent to the Python expression

{\tt D[key1][key2][key3]}.

There are no error conditions associated with this predicate.

\ourrepeatmoditem{keys(+Dict,?Keys)}{keys/2}{xp\_utils}
\altourmoditem{items(+Dict,?Items)}{items/2}{xp\_utils}
%
Convenience predicates (for the inveterate Python programmer) to
obtain a list of keys or items from a Prolog dictionary.  There are no
error conditions associated with these predicates.



\altourmoditem{obj\_dict(+ObjRef,-Dict)}{obj\_dict/2}{xp\_utils}
%
Given a reference to a Python object as {\tt ObjRef}, this predicate
returns the dictionary of attributes of {\tt ObjRef} in {\tt Dict}.
If no \_\_dict\_\_ attribute is associated with {\tt ObjRef} the
predicate fails.

{\tt obj\_dict/2} is a convenience predicate, and could be written
using {\tt pydot/4} as:

\begin{verbatim}
  pydot('__main__',Obj,'__dict__',Dict).
\end{verbatim}

\altourmoditem{obj\_dir(+ObjRef,-Dir)}{obj\_dir/2}{xp\_utils}
%
Given a reference to a Python object as {\tt ObjRef}, this predicate
returns the list of attributes of {\tt ObjRef} in {\tt Dir}.  If no
\_\_dir\_\_ attribute is associated with {\tt ObjRef} the predicate
fails.

{\tt obj\_dir/2} is a convenience predicate, and could be written
using {\tt pydot/4} as:

\begin{verbatim}
  pydot('__main__',Obj,'__dir__'(),Dir).
\end{verbatim}

\end{description}

\section{Allowing Python to Reclaim Space}
%
TBD: Discuss space issues for Python how they are now addressed and
how they will be addressed in the future.

\section{Performance}

The core {\tt xsbpy} routines -- {\tt pyfunc/[3,4]} and {\tt pydot/4}
-- are written almost entirely in C, have shown good performance so
far, and continue to be optimized.  Calling a simple Python function
to increment a number from XSB and then returning the incremented
value to XSB should take about a microsecond on a reasonably fast
machine.  Of course, the overhead for passing large terms from and to
Python will be somewhat higher.  For instance, the time to pass a list
of integers from Python to XSB has been timed at about 20-30
nanoseconds per list element.  Nonetheless, for nearly any practical
application the time to perform useful functionality within Python
will far outweigh any {\tt xsbpy} overhead.

Apart from system resource limitations, there is virtually no upper
limit on the size of Python structures passed back to Prolog: stress
tests have passed lists of length 100 million from Python to Prolog
without problems. However, it should be noted that {\tt xsbpy} must
ensure that XSB's heap is properly expanded before copying a large
structure from Python to XSB.  XSB currently uses size routines from
the Python C-API which only return the length of structures, and not
their exact size.  Accordingly long lists of large structures, heavily
nested dictionaries and other such structures may currently present a
problem.  This will be addressed in a future version, but until then a
user can reset the {\tt heap\_margin} Prolog flag to ensure extra
stack space beyond that allocated by {\tt xsbpy} (see Volume 1 for
details.)

\section{Interfaces to Python Libraries}

The {\tt starters} directory contains code to interface to various
Python libraries -- and so to start using XSB and Python together to
solve problems and do research.  Some of the files implement useful
higher level mappings that translate say, embedding spaces or Spacy
graphs to Prolog graphs, or translate RDF graphs to lists of Prolog
structures.  Others are collections of examples to show how to query
or update Elasticsearch, to detect the language of input text or to
perform machine translation.  Nearly all of the interfaces have been a
starting point for research or commercial
applications.  \footnote{Testing has been done of the interfaces, but
  the testing has not been exhaustive.  As a result, please
  double-check any results, and report bugs -- or improvements -- to
  {\tt xsb.sorceforge.net}.}

When {\tt xsbpy} is loaded, both the {\tt xsbpy} directory and its
{\tt starters} subdirectory is added to the Prolog and Python paths.
As a result, modules in these subdirectories can be loaded into XSB
and Python without changing their library paths.

Note that most of these applications require the underlying Python
libraries to have been installed via a {\tt pip} or {\tt conda}
install.

\subsection{Dense Vector Queries with xp\_faiss}
The dense-vector query engine Faiss \cite{JDH17}, developed by
Facebook offers an efficient way to perform nearest neighbor searches
in vector spaces produced by word, network, tuple, or other
embeddings.  The {\tt xp\_faiss} example provides XSB predicates to
initialize a Faiss index from a text file of vectors, perform queries
to the index, and to make a weighted Prolog graph out of the vector
space.  

As with many machine-learning tools, Faiss expects that each of the
vectors is referenced by an integer.  For instance, a vector for the
string {\em cheugy} would be referenced by an integer, say 37.  The
XSB programmer thus would be responsible for associating the string
{\em cheugy} with 37 in order to use Faiss.  The main predicates
exported by {\tt xp\_faiss.P} include:

\begin{itemize}
\item {\tt faissInit(+XbFile,+Dim)} initializes a Faiss index where
  {\tt XbFile} is a text file containing the vectors to be indexed and
  {\tt Dim} is the dimension of these vectors. ({\tt xb} is Faiss
  terminology for the set of {\em base}, i.e., indexed, vectors.)
  This predicate also creates a {\tt numpy} array with a set of query
  vectors {\tt xq} consisting of the same vectors.  When the query and
  index vectors are set up in this manner, a nearest-neighbor search
  can be performed for any of the indexed vectors.  With this, the
  vector space can be explored, visualized, and so on.

  After execution of this predicate, a fact for the predicate {\tt
    xp\_faiss:xq\_num/1} contains the number of query vectors ({\tt
    xq}), which is the same as the number of indexed vectors ({\tt
    xb}).

\item {\tt get\_k\_nn(+Node,+K,-Neighbors)} finds the {\tt K} nearest
  neighbors of a node.  The predicate takes as input {\tt Node}, the
  integer identifier of a node, and {\tt K} the number of nearest
  neighbors to be returned.  The return structure {\tt Neighbors} is
  the Prolog representation of a 2-ary Python tuple (i.e., {\tt ''/2})
  containing as its first argument a list of {\tt K} distances and as
  it second argument a list of {\tt K} neighbors.


\item {\tt make\_vector\_graph(K)} Given a Faiss index, this predicate
  asserts a weighted graph in Prolog by obtaining the nearest {\tt K}
  neighbors for each indexed vector.  Edges of the graph have the form:

  {\tt vector\_edge\_raw(From,To,Dist)}

  \noindent
  Where {\tt From} and {\tt To} are integer referents for indexed
  vectors, and {\tt Dist} is the Euclidean distance between the vector
  with referent {\tt From} and the vector with referent {\tt To}.
  Each fact of {\tt vector\_edge\_raw/3} is indexed both on its first
  and second argument.

  If both the number of indexed vectors and {\tt K} are large,
  construction of the Prolog vector graph may take a few minutes.
  Construction time is almost wholly comprised of the time to find the
  set of nearest neighbors for each node.

\item {\tt vector\_edge(Node1,Node2,Dist)}.  The vector graph, which
  represents distances is undirected.  However to save space, the {\tt
    vector\_edge\_raw/3} facts are asserted so that if {\tt
    vector\_edge\_raw(Node1,Node2,Dist}) has been asserted, {\tt
    vector\_edge\_raw(Node2,Node1,Dist}) will not be asserted.  {\tt
    vector\_edge/3} calls {\tt vector\_edge\_raw/3} in both
  directions, and should be used for querying the vector graph.
  
\item {\tt write\_vector\_graph(+File,+Header)} writes out the vector
  graph to {\tt File}.  This predicate ensures that {\tt File}
  contains the proper indexing directive for {\tt vector\_edge\_raw/3}
  as well a directive to the compiler describing how to dynamically
  load {\tt File} in an efficient manner.  Because of these
  directives, the file can simply be consulted or ensure\_loaded and
  the user does not need to worry about which compiler options should
  be used.  The graph is loaded into the module {\tt vector\_graph}.

  {\tt Header} is simply a string that is written as a comment to the
  first line of {\tt File} that can serve to contain any necessary
  provenance information.
\end{itemize}  

\subsection{Translating Between RDF and Prolog: xp\_rdflib} \label{secLxp-rdflib}
This module interfaces to the Python {\tt rdflib} library to read RDF
information from files in Turtle, N-triples and N-quads format, and to
write files in Turtle and N-triples format.  As such it augments XSB's
RDF package (Chapter~\ref{chapter:RDF}) which handles
XML-RDF.

Within a triple, URIs and blank nodes are returned as Prolog atoms,
while literals are returned as terms with functor {\tt ''/3} (the
Prolog representation of a 3-ary tuple) in which the first argument is
the literal's string as a Prolog atom, the second argument is its
datatype, and the third argument its language. If the data type or
language are not included, the argument will be null.  As examples:

\begin{verbatim}
"That Seventies Show"^^<http://www.w3.org/2001/XMLSchema#string> 
\end{verbatim}
is returned as 
\begin{verbatim}
("That Seventies Show",'<http://www.w3.org/2001/XMLSchema#string>',) 
\end{verbatim}
while 
\begin{verbatim}
"That Seventies Show"@en
\end{verbatim}
is returned as
\begin{verbatim}
("That Seventies Show",,en) 
\end{verbatim}

The file {\tt xp\_rdflib.P} contains predicates {\tt test\_nt/0}, {\tt
  test\_ttl/0}, {\tt test\_nq/0} to test reading and writing.  Note
that Python options needed to deserialize an RDFllb graph write are
specific to the RDFlib plug-in for a particular format, and these
plug-ins are not always consistent with one another.  As a result, if
other formats are desired, minor modifications of {\tt xp\_rdflib} may
be necessary.

\paragraph{Reading RDF}
\begin{itemize}
\item {\tt read\_rdf(+File,+Format,-TripleList)} reads RDF from a file
  containing an RDF graph formatted as {\tt Format}, where the formats
  {\tt turtle}, {\tt nt} and {\tt nquads} have been tested.  These
  formats can be tested on {\tt sample.ttl}, {\tt sample.nt} and {\tt
    sample.nq}, all of which are in the {\tt starters} directory.

  Due to the structure of the Python {\tt RDFlib} graph, no guarantee
  is made that the order of facts in {\tt File} will match the order
  of facts in {\tt TripleList}.
\end{itemize}
  
{\bf Error Cases}
\bi
\item {\tt Format} is not {\tt nt}, {\tt turtle} or {\tt nquads}
\bi
\item misc\_error
\ei
\end{itemize}

\paragraph{Writing RDF}

If {\tt TripleList} is a list of terms, structured as {\tt ''/3} terms
described above, it can be easily be written to {\tt File} as properly
formatted RDF.  The Python function {\tt
  rdflib\_write\_file\_no\_decode()} can be called directly as:
\begin{verbatim}
pyfunc(xp_rdflib,rdflib_write_file_no_decode(+TripleList,+File),[format=+Fmt],-Ret).
\end{verbatim}
where {\tt Fmt} is {\tt turtle} or {\tt nq}.  {\tt
  rdflib\_write\_file\_no\_decode()} is a simple function that creates
an RDFlib graph out of {\tt TripleList}, serializes the graph and
prints it out.  The Python options needed to write to a file are
specific to the RDFlib plug-in for a particular format, so if other
formats are desired, minor modifications of {\tt xp\_rdflib} may be
necessary.

Due to the structure of the Python {\tt RDFlib} graph, no guarantee is
made that the order of facts in {\tt File} will match the order of
facts in {\tt TripleList}.
  
\subsection{xp\_spacy}
Spacy is a well-known and widely used tool that exploits neural
language models to analyze text via dependency parses, named entity
recognition, and much else.  Although Spacy is a Python tool, much of
it is written in C/Cython which makes it highly efficient.  The {\tt
  xp\_spacy} package offers a flexible and efficient means to use
Spacy from Prolog (once Spacy has been properly installed for Python).

In Spacy, a user first loads one or more language models for the
language(s) of interest and of a size suitable to the application.
Text is then run through this language model and through other Spacy
code producing a {\em document} containing a great amount of detail
about the sentences in the text, tokens in the sentence and their
relations to one another.

The predicate {\tt load\_and\_proc/2} loads a Spacy model and
processes text, asserting Python references both to the document and
to the function used to invoke the language model on text.  At this
point, a user of {\tt xsbpy} has two options: she can either query the
document directly or call {\tt token\_assert} to assert information
from the document into a Prolog graph that can be conveniently
analyzed.  If querying a document directly, a small amount of code may
need to be written because Spacy's API often returns generators to its
data structures rather than its data structures themselves.  Generally
the code that needs to be written is extremely simple and consists of
little more than a list comprehension: the functions {\tt get\_nps()},
{\tt get\_ents()} and {\tt get\_token\_info()} in {\tt xp\_spacy.py}
provide examples of this.

For most purposes however, it is easier to call the XSB predicate {\tt
  token\_assert()} that asserts tokens and their dependency parse
edges into XSB as explained below.  As an example of how to navigate
this graph, {\tt show\_all\_trees/0} and its supporting predicates
provide a simple but clear representation of the Spacy dependency
parse in tree form using the Prolog version of the parse.

The code in this package originated as part of a large research
project and reflects the needs of that project.  Other applications
may have slightly different needs, and the {\tt xp\_spacy} code can be
easily refactored to support such needs.

As a final point before presenting the the main predicates, note that
if text from different languages is to be analyzed, the package {\tt
  xp\_fasttext} can be used to determine the language of a text
string, and the text can then be sent to one of several language
models. \footnote{The predicates provided will need a slight
  refactoring for this.}.

\begin{itemize}
\item {\tt load\_and\_proc(Model,File)} loads the Spacy model {\tt
  Model} and processes the text file {\tt File}.  If successful, it
  asserts two facts to usermod to reference the language model and the
  document processed from the text in {\tt File}:
\begin{verbatim}  
    assert(python_obj(nlp,NLP)),
    assert(python_obj(doc,Doc)).
\end{verbatim}

If the language model has been loaded, another file can be processed via:
\begin{verbatim}
    pyfunc(xp_spacy,doc_from_file(File,NLP),Doc),                              
\end{verbatim}
and similar functions can be used to parse strings directly, etc.

\item {\tt token\_assert()} This predicate calls the Prolog fact {\tt
  python\_obj(doc,Doc)}, accesses the dependency graph and other
  information from the Spacy document and asserts it to Prolog as a
  graph.  The Prolog form of the graph uses two predicates:
\begin{verbatim}  
    token_info_raw(Index,Text,Lemma,Pos,Tag,Dep,EntType),
\end{verbatim}
represents the nodes of the graph.  For a given {\em token} its fields
are as follows:
\begin{itemize}
  \item {\tt Index} ({\tt token.idx}) is the character offset of {\em
    token} within the document, and serves as an index for the token
    both in Spacy and in its Prolog representation.
  \item {\tt Text} ({\tt token.text}) the verbatim form of {\em token}
    in the text that was processed.
  \item {\tt Lemma} ({\tt token.lemma\_}) the base form of {\em
    token}.  If {\em token} is a verb, {\tt Lemma} is its stem, if
    {\em token} is a noun, {\tt Lemma} is its singular form.
  \item {\tt Pos} ({\tt token.pos\_ }) is the coarse-grained part of
    speech for {\em token} according to {\tt
      https://universaldependencies.org/docs/u/pos}
  \item {\tt Tag} ({\tt token.tag\_ }) The fine-grained part of speech
    for {\em token} that contains some morphological analysis in
    addition to the part-of-speech.
    (cf.

    {\tt https://stackoverflow.com/questions/37611061/spacy-token-tag-full-list}

    
      for a discussion of its meaning and use.
  \item {\tt Dep} ({\tt token.dep\_ }) The type of relation that {\em
    token} has with its parent in the dependency graph.
  \item {\tt EntType} ({\tt token.ent\_type\_ }) The Spacy named entity
    type, e.g., person, organization, etc.
\end{itemize}  

Edges of the Prolog graph have the form:
\begin{verbatim}
token_childOf(ChildIndex,ParentIndex)
\end{verbatim}
where {\tt ChildIndex}, and {\tt ParentIndex} are indexes for {\tt
  token\_info\_raw/7} facts.

Note that Spacy tokens have many other attributes, of which the above
are some of the more useful.  If other attributes are needed, the {\tt
  xp\_spacy} code can easily be expanded to include them.  However
many aspects of the parse can be easily reconstructed by the Prolog
graph: for instance {\tt xp\_spacy.P} contains code for constructing
sentences, subtrees of a given token and so on.

\item {\tt token\_info(Index,Text,Lemma,Pos,Tag,Dep,Ent\_type)} is a
  convenience predicate that calls {\tt token\_info\_raw/7} and
  filters out spaces and punctuation.
  
\item {\tt show\_all\_trees()} Given a Spacy graph asserted to Prolog
  as described above, {\tt show\_all\_trees/0} navigates the graph,
  and for each sentence in the graph converts the dependency graph to
  a tree and prints it out.  This predicate is useful for reviewing
  parses, and its code in {\tt xp\_spacy.P} can be modified and
  repurposed for other needed functionality.

  As an example, if the graph contained the sentence:
\begin{verbatim}  
Want to experience what it's like to fly a drone?  
\end{verbatim}  
{\tt show\_all\_trees/0} would print out:
\begin{verbatim}
     token_info(1,Want,want,VERB,VB,ROOT,)
        token_info(9,experience,experience,VERB,VB,xcomp,)                                   
           token_info(6,to,to,PART,TO,aux,)                                                  
           token_info(27,’s,’,VERB,VBZ,ccomp,)                                               
             token_info(25,it,it,PRON,PRP,nsubj,)  
             token_info(30,like,like,ADP,IN,prep,)                                           
                token_info(20,what,what,PRON,WP,pobj,)                                       
          token_info(38,fly,fly,VERB,VB,xcomp,)                                              
             token_info(35,to,to,PART,TO,aux,)                                               
             token_info(48,drone,drone,NOUN,NN,dobj,)      
                token_info(42,a,a,DET,DT,det,)                                              \
\end{verbatim}
\end{itemize}  

\subsection{xp\_json}
This module contains an interface to the Python {\tt json} module,
with predicates to read JSON from and write JSON to files and strings.
The {\tt json} module transforms JSON objects into and from Python
dictionaries, which the interface maps to and from their term forms.
This module can be used to help understand how Python dictionaries
relate to XSB terms, or as an alternative to XSB's native Json package
({\tt json} Chapter~\ref{chap:json}).  For instance, while for most
purposes the {\tt json} package should be used, {\tt xp\_json} can be
useful if the json constructed and read comes from another {\tt xsbpy}
application such as {\tt xp\_elastic}.  This is because the format
used by {\tt xp\_json} maps directly to a Python dictionary, while
that of the {\tt json} package maps to other (very useful) formats.

The {\tt xp\_json} functions are written in Python and can be
called directly from Prolog.
\begin{itemize}
\item {\tt pyfunc(xp\_json,prolog\_load(+File),+Features,-Json)}
  opens and reads {\tt File} and returns its Json content in {\tt
    Json} as a Prolog dictionary term.
\item {\tt pyfunc(xp\_json,prolog\_dump(+Dict,+File),+Features,-Ret)}
  converts {\tt Dict} to a Json object, write it to {\tt File} and
  returns the result of the operation in {\tt Ret}.
\item {\tt pyfunc(xp\_json,prolog\_loads(+Atom),+Features,-Json)}
  reads the atom {\tt Atom} and returns its Json content in {\tt Json}
  as a Prolog dictionary term.
\item {\tt  pyfunc(xp\_json,prolog\_dumps(+Dict),+Features,-JsonAtom)}
  converts {\tt Dict} to a Json string, and returns the string as the
  Prolog atom {\tt JsonAtom}.
\end{itemize}  

\subsubsection{Other Examples and Demos}

\paragraph{xp\_elastic}
This module contains sample code for using the Python {\tt
  elasticsearch} package.  A step by step description shows how a
connection is opened, and index is created and a document added and
committed.  The example then shows how the document can be searched in
two ways, and finally deleted.

Much of the information that Elasticsearch reads and writes is in JSON
format, which the Python interface transforms to dictionaries, and
{\tt xsbpy} transforms these dictionaries to and from their term form.
Thus although this example is short, the ideas in it can easily be
extended to a full interface.~\footnote{This has already been done by
  one company that uses XSB.}  Often the {\tt elasticsearch} functions
can be called directly, but in certain cases simple Python functions
must be written to handle default positional arguments. \footnote{{\tt
    xsbpy} correctly handles default keyword arguments, but the Python
  C API does not seem to support default positional arguments.}

\paragraph{Fasttext Language Detection: xp\_fasttext}
%
Facebook's {\tt fasttext} provides a collection of functionality
including word vectors for 176 languages, the language-alignment tool
Muse, and the language identification tool {\tt lid.176.bin},.  This
module provides example code to help the user get started using
Fasttext's language detection, and relies on the python module {\tt
  fasttext}.  Assuming that Fasttext's language identification module
is in the current directory, the command:
\begin{verbatim}
 pyfunc(fasttext,load_model('./lid.176.bin'),Obj).
\end{verbatim}
Loads the model and unifies {\tt Obj} with a reference to the loaded
module which might look like {\tt pyObj(p0x7faca3428510)}.  
Next, a call to the example python module {\tt xp\_fasttext}:
\begin{verbatim}
pyfunc(xp_fasttext, fasttext_predict(pyObj(p0x7faca3428510),
       'xsbpy is a really useful addition to XSB! But language detection
        requires a longer string than I usually want to type.'),Lang).  
\end{verbatim}
returns the detected language and confidence value, which in this case
is {\tt (\_\_label\_\_en,0.93856)}.

Note that loading the model can be done by calling the Python {\tt
  fasttext} module directly.  In fact, the only reason that the module
{\tt xp\_fasttext} needs to be used (as opposed to calling the Python
functionality directly) is because the confidence of the language
detection is returned as a {\tt numpy} array, which {\tt xsbpy} does
not currently translate automatically. \footnote{The examples {\tt
    xp\_fasttext} and {\tt googleTrans} were written by Albert Ki;
  {\tt xp\_faiss} was written by Albert Ki and Theresa Swift.}

\paragraph{xp\_googleTrans}
This example provides demo code to access Google's web-services for
language translation and language detection using {\tt xsbpy}.

%\paragraph{mpl}
%This file has a simple example of how to create, display, and save as
%pdf a simple matplotlib document.

\section{Current and Future Work}

\begin{itemize}
\item A callback mechanism is under development.  This mechanism
  allows XSB and Python to recursively call each other.  Our intention
  is to make our callback mechanism consistent with PyXSB, {\tt
    pypi.org/project/py-xsb}, but currently PyXSB and {\tt xsbpy} are
  independent of each other.

\item A possible future version may include a hook in XSB's atom
  garbage collection to list Python objects that may be garbage
  collected, and to send this information back to Python.  
\end{itemize}  

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "manual2"
%%% End: 
